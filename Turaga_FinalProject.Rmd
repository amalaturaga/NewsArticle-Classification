---
name: "Amala Turaga"
title: "Turaga_FinalProject"
output: html_document
date: "2023-11-28"
---
Task One (Prescriptive Part):

1. Read in data set
```{r}
library(tidyverse)
url <- "https://www4.stat.ncsu.edu/~online/ST308/Data/asturaga_house.csv"
asturaga_data <- read_csv(url)
```
2. Create new tibble to alter data (remove data & create new variables)
```{r}
alter_data <- asturaga_data %>%
 #remove observations w/ these conditions
  filter(!(MasVnrType == "Stone" | OpenPorchSF <= 0)) %>%
 #create new variable
  mutate(newSalePrice = SalePrice / 100000) %>%
 #remove these two variables
  select(-BedroomAbvGr, -LandSlope)

library(knitr)
kable(alter_data[1:10, 1:6])
```
3. Produce summary statistics
```{r}
summary_house <- alter_data %>%
  group_by(LotConfig) %>%
  summarize(SalePrice_mean = mean(SalePrice),
            SalePrice_sd = sd(SalePrice),
            SalePrice_q1 = quantile(SalePrice, 0.25),
            SalePrice_q3 = quantile(SalePrice, 0.75),
            YearRemodAdd_mean = mean(YearRemodAdd),
            YearRemodAdd_sd = sd(YearRemodAdd),
            YearRemodAdd_q1 = quantile(YearRemodAdd, 0.25),
            YearRemodAdd_q3 = quantile(YearRemodAdd, 0.75),
            BsmtFinSF1_mean = mean(BsmtFinSF1),
            BsmtFinSF1_sd = sd(BsmtFinSF1),
            BsmtFinSF1_q1 = quantile(BsmtFinSF1, 0.25),
            BsmtFinSF1_q3 = quantile(BsmtFinSF1, 0.75))
kable(summary_house)
```
4. Create a scatter plot
```{r}
ggplot(alter_data, aes(x = YearRemodAdd, y = SalePrice, color = LotConfig)) + geom_point()
```

Looking at the graph above, it can be seen that majority of the data points are concentrated closer to the year 2000 and later. This also shows that most houses are in the 15,000-35,000 dollar range. We can also see that the LotConfig of "Inside" is the color that can be seen the most on the graph.

5. Create the same plot (ExterCond)
```{r}
ggplot(alter_data, aes(x = YearRemodAdd, y = SalePrice, color = LotConfig)) + geom_point() + facet_wrap(~ ExterCond)
```

Task Two (Open Ended Part):

1. I am currently a Computer Science major and am in the process of completing a CODA into Statistics. Both of these majors use and manipulate data in different ways but are essentially\ trying to do so in similar ways. Having the technical skillset and the statistical mindset is something that is very useful when it comes to working with big data and how that information helps to solve everyday problems.

2. The dataset I will be using is a dataset that has ranked the top universities all over the world and has given each one a score based on a few metrics. I think that this dataset is interesting because it can help to solve three main points of problems when looking to choices about higher education. It can be used to understood why some of the top universities are the top and what methods they are using to make their institutions so successful, it can be used to help with resource allocation to universities and understand where there is a gap, and finally with helping prospective students understand what universities are for them and how to take advantage of the opportunities each one can offer for their future. For the next question, I will only be using the data file from "The Global Top 10 data file". 

URL: https://www.kaggle.com/datasets/meeratif/top-universities-ranks-global-and-continent-wise?resource=download

Each variable describes the year from 2018 to 2024. The observations of those years describes the rankings of the universities each year based on factors such as academic performance, research output, and reputation. All the variables are numerical since they are rankings on a certain scale. 

3. Read in the data
```{r}
library(readr)
global_university <- read_csv("/Users/amalaturaga/ST 308/Global Top 10.csv")
```
4. Create a custom function for summaries
```{r}
#Create a sample data frame
university_data <- data.frame(
  University = c(
    "Massachusetts Institute of Technology (MIT)",
    "University of Cambridge",
    "University of Oxford",
    "Harvard University",
    "Stanford University",
    "Imperial College London",
    "ETH Zurich",
    "National University of Singapore",
    "University College London",
    "University of California, Berkeley"
  ),
  Year_2018 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, NA),
  Year_2019 = c(1, 2, 4, 5, 3, 6, 9, 11, 8, NA),
  Year_2020 = c(1, 3, 1, 5, 3, 7, 8, 11, 8, NA),
  Year_2021 = c(1, 7, 5, 3, 2, 8, 6, 11, 10, NA),
  Year_2022 = c(1, 7, 4, 3, 2, 9, 6, 11, 8, NA),
  Year_2023 = c(1, 6, 5, 3, 2, 8, 7, 11, 10, NA),
  Year_2024 = c(1, 5, 6, 3, 2, 8, 10, 15, 7, NA)
)

#Function to compute summary stats
summary_stats <- function(data, columns = NULL) {
  #All columns used except for header if not specified
  if (is.null(columns)) {
    columns <- names(data)[-1]
  }
  
  #Summary statistics for numeric columns (years)
  numeric_summary <- data %>%
    summarise_at(vars(all_of(columns)), list(
      Mean = ~mean(., na.rm = TRUE), 
      Median = ~median(., na.rm = TRUE),
      SD = ~sd(., na.rm = TRUE), 
      IQR = ~IQR(., na.rm = TRUE),
      Quantile_0_1 = ~quantile(., 0.1, na.rm = TRUE), 
      Quantile_0_9 = ~quantile(., 0.9, na.rm = TRUE)
    ))
  return(numeric_summary)
}
```
5. Apply functions in different scenarios
```{r}
#Scenario 1: Summary stats for one column (Year_2018)
summary_2018 <- summary_stats(university_data, columns = "Year_2018")
print(summary_2018)

#Scenario 2: Summary stats for two columns (Year_2018 and Year_2019)
summary_2018_2019 <- summary_stats(university_data, columns = c("Year_2018", "Year_2019"))
print(summary_2018_2019)

#Scenario 3: Summary stats for all numeric columns (all years)
summary_all_years <- summary_stats(university_data)
print(summary_all_years)
```













